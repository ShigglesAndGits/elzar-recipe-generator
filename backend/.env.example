# Grocy Configuration
GROCY_URL=https://your-grocy-instance.com
GROCY_API_KEY=your_grocy_api_key_here

# LLM Configuration
# OpenRouter example (recommended for free Gemini access):
LLM_API_URL=https://openrouter.ai/api/v1
LLM_API_KEY=your_openrouter_api_key_here
LLM_MODEL=google/gemini-2.0-flash-exp:free

# OpenAI example:
# LLM_API_URL=https://api.openai.com/v1
# LLM_API_KEY=your_openai_api_key_here
# LLM_MODEL=gpt-4

# Ollama example (local):
# LLM_API_URL=http://localhost:11434/v1
# LLM_API_KEY=ollama
# LLM_MODEL=llama2

# Optional Settings
MAX_RECIPE_HISTORY=50
APPRISE_URL=
UNIT_PREFERENCE=imperial
BACKEND_PORT=8001
